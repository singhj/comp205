{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-dimensional arrays\n",
    "\n",
    "Since we _happen_ to be working on this section after having covered 03-03-data-ingest, this notebook encompasses elements of both!\n",
    "\n",
    "## 1. Obtain the data \n",
    "\n",
    "For this exercise, we'll be downloading data ourselves. The [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) is a widely used resource that hosts over 500 data sets. For this exercise, we will be using the [Dow Jones Index Data Set](https://archive.ics.uci.edu/ml/datasets/dow+jones+index). This landing page is typical for a dataset:\n",
    "* It says something about the dataset and also provides key metrics about it, such as Number of Instances (rows), Number of Attributes (columns).\n",
    "* Near the top, it has two links: _Download:_ Data Folder, Data Set Description.\n",
    "\n",
    "Clicking on [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/00312/) on the landing page brings you to a page that provides a download link for the data.\n",
    "\n",
    "1. Click on the zip file link to download the data to your machine.\n",
    "2. Unzip the downloaded file.\n",
    "3. Drag and drop the `dow_jones_index.data` file into your Jupyter folder.\n",
    "4. Take a look at the downloaded file by executing the next cell.\n",
    "\n",
    "If the next cell shows the data, you have succeeded in downloading it to the correct location. If not, move it to the right place in your workspace until it shows there &mdash; _Drag and drop_ is your friend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quarter,stock,date,open,high,low,close,volume,percent_change_price,percent_chang\n",
      "e_volume_over_last_wk,previous_weeks_volume,next_weeks_open,next_weeks_close,per\n",
      "cent_change_next_weeks_price,days_to_next_dividend,percent_return_next_dividend\n",
      "1,AA,1/7/2011,$15.82,$16.72,$15.78,$16.42,239655616,3.79267,,,$16.71,$15.97,-4.4\n",
      "2849,26,0.182704\n",
      "1,AA,1/14/2011,$16.71,$16.71,$15.64,$15.97,242963398,-4.42849,1.380223028,239655\n",
      "616,$16.19,$15.79,-2.47066,19,0.187852\n",
      "1,AA,1/21/2011,$16.19,$16.38,$15.60,$15.79,138428495,-2.47066,-43.02495926,24296\n",
      "3398,$15.87,$16.13,1.63831,12,0.189994\n",
      "1,AA,1/28/2011,$15.87,$16.63,$15.82,$16.13,151379173,1.63831,9.355500109,1384284\n",
      "95,$16.18,$17.14,5.93325,5,0.185989\n",
      "1,AA,2/4/2011,$16.18,$17.39,$16.18,$17.14,154387761,5.93325,1.987451735,15137917\n",
      "3,$17.33,$17.37,0.230814,97,0.175029\n",
      "1,AA,2/11/2011,$17.33,$17.48,$16.97,$17.37,114691279,0.230814,-25.71219489,15438\n",
      "7761,$17.39,$17.28,-0.632547,90,0.172712\n",
      "1,AA,2/18/2011,$17.39,$17.68,$17.28,$17.28,80023895,-0.632547,-30.22669579,11469\n",
      "1279,$16.98,$16.68,-1.76678,83,0.173611\n",
      "1,AA,2/25/2011,$16.98,$17.15,$15.96,$16.68,132981863,-1.76678,66.17769355,800238\n",
      "95,$16.81,$16.58,-1.36823,76,0.179856\n",
      "1,AA,3/4/2011,$16.81,$16.94,$16.13,$16.58,109493077,-1.36823,-17.66315005,132981\n",
      "863,$16.58,$16.03,-3.31725,69,0.180941\n",
      "1,AA,3/11/2011,$16.58,$16.75,$15.42,$16.03,114332562,-3.31725,4.419900447,109493\n",
      "077,$15.95,$16.11,1.00313,62,0.187149\n",
      "\u001b[7m--More--(1%)\u001b[m"
     ]
    }
   ],
   "source": [
    "!more dow_jones_index.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the following:\n",
    "* There are 16 columns in the data, \n",
    "* Some columns are integers, others are strings or dates or money (starting with `$`), etc.\n",
    "\n",
    "We will be reading the data into our notebook step by step.\n",
    "\n",
    "First, instead of having to type column names into your code, it's good practice to copy-and-paste from the output of the previous command, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy-paste the header from the output of the previous cell into the next line...\n",
    "\n",
    "colnames = 'column names from output of previous cell'.split(',')\n",
    "print (colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python's concept of dates and times\n",
    "\n",
    "Native Python doesn't have any concept of date and time. The [datetime package](https://docs.python.org/3/library/datetime.html) provides these concepts in a library. The package supports a number of classes for representing a set of related concepts. \n",
    "\n",
    "In addition, numpy provides the data type called “datetime64”, so named because “datetime” is already taken by the datetime library included in Python. See [Numpy Datetimes and Timedeltas](https://numpy.org/doc/stable/reference/arrays.datetime.html) for more details.\n",
    "\n",
    "In this notebook we will focus on Python's native **datetime**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read just the first three columns\n",
    "\n",
    "We will define a variable `cols_to_take` as 3 at first, then progressively increase it to process more and more of the data. Execute the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_take = 3\n",
    "dtype={'names': tuple(colnames[:cols_to_take]),\n",
    "       'formats': ('i4', 'S8', 'S10')}\n",
    "dji_1 = np.loadtxt('dow_jones_index.data', dtype=dtype, \\\n",
    "                    comments='#', delimiter=',', skiprows=1, usecols=[col for col in range(cols_to_take)])\n",
    "dji_1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. What do `b'AA'` or `b'1/7/2011'` mean?\n",
    "\n",
    "`b'whatever'` is like a string but different. To be specific, it's a 'byte string'. We won't delve into much detail here except to show the following example where `print(dt.strptime(begin_date, '%m/%d/%Y'))` fails. We have to explicitly decode the byte string into a character (Unicode) string using the `'utf-8'` encoding scheme. [More about character encoding](https://www.w3.org/International/questions/qa-what-is-encoding) in case you are curious!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "begin_date = b\"1/7/2011\"\n",
    "try:\n",
    "    print(dt.strptime(begin_date, '%m/%d/%Y'))\n",
    "except TypeError:\n",
    "    print ('Failed type check')\n",
    "    print (dt.strptime(str(begin_date, 'utf-8'), '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.strptime('1/14/2011', '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reload the first three columns, with column 2 as a datetime.\n",
    "\n",
    "We will read the date field and store it as a [UNIX time](https://en.wikipedia.org/wiki/Unix_time). It is the number of seconds that have elapsed since the Unix epoch, minus leap seconds; the Unix epoch is 00:00:00 UTC on 1 January 1970 (an arbitrary date); leap seconds are ignored.\n",
    "\n",
    "It's worthwhile to convert one of these values back to a date format to be satisfied that it works and we can convert that value back to the date when needed!\n",
    "\n",
    "The next cell converts a datetime object (initialized from bytes b\"1/14/2011\"), then converts it to a UNIX timestamp, converts it back to the datetime object and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "date_in = b\"1/14/2011\"\n",
    "\n",
    "def convert_date(date_bytes):\n",
    "    return dt.strptime(str(date_bytes, 'utf-8'), '%m/%d/%Y').timestamp()\n",
    "\n",
    "dt.fromtimestamp(convert_date(date_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to read in the first three columns of the data. Notice that column 2 (the third column) is declared as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype={'names': tuple(colnames[:cols_to_take]),\n",
    "       'formats': ('i4', 'S8', 'f4')}\n",
    "\n",
    "dji_2 = np.loadtxt('dow_jones_index.data', dtype=dtype, ... fill in ...)\n",
    "dji_2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Validate date values in column 2.\n",
    "\n",
    "It's worthwhile to convert one of these values back to a date format to be satisfied that it works and we can convert that value back to the date when needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fromtimestamp(1.2943764e+09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert the stock price values\n",
    "\n",
    "The stock prices are prepended with a `$` sign. \n",
    "Write a converter for stripping it from the string and storing the price **as an integer as number of cents**. \n",
    "Rewrite the code above to read the prices in addition to the first three columns. \n",
    "You will now have 7 columns in your output.\n",
    "\n",
    "Why did we convert prices from dollars to pennies? Floating point numbers don't always accurately represent dollar values. You may have seen output showing price as 39.000000001 or 40.999999999. To ensure that we don't run into this problem, we convert the dollars to pennies and store the result as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Validate volume data\n",
    "\n",
    "Three attributes are related: `'volume'` ( v<sub>this week</sub> ), `'previous_weeks_volume'` (v<sub>last week</sub>) and `'percent_change_volume_over_last_wk'` (&Delta;v expressed as a fraction). \n",
    "\n",
    "* For some records, the previous week's figures are not available as they are the beginning of a period. Skip those comparisons.\n",
    "* For all other records, show the records where\n",
    "    v<sub>this week</sub> &ne; ( v<sub>last week</sub> &times; ( 1 + &Delta;v)). \n",
    "They should be identical, right?\n",
    "\n",
    "Hint: use a technique similar to the exercise in the [original notebook](03-02-multi-dimensional-data.ipynb) to examine all rows whose elements are more than 1 standard deviation from the mean for the respective columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done, submit the notebook\n",
    "\n",
    "1. **Run all the cells in order.**\n",
    "\n",
    "2. Submit the notebook by saving it as PDF. \n",
    "    * In the cluster environment, it's File | Print (Save as PDF) and submit to [Gradescope](https://www.gradescope.com/courses/182658)<sup>&dagger;</sup>, \n",
    "    * On other versions, it may be File | Download As (PDF) and then submit to [Gradescope](https://www.gradescope.com/courses/182658)<sup>&dagger;</sup>.\n",
    "\n",
    "<sup>&dagger;</sup>To submit to Gradescope, log into the website, add course 9W7PW3 (if not already added) and submit. The assignment name should match the name of this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
