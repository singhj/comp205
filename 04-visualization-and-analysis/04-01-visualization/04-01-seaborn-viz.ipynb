{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"../../figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Geographic Data with Basemap](04.13-Geographic-Data-With-Basemap.ipynb) | [Contents](Index.ipynb) | [Further Resources](04.15-Further-Resources.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.14-Visualization-With-Seaborn.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib has proven to be an incredibly useful and popular visualization tool, but even avid users will admit it often leaves much to be desired.\n",
    "There are several valid complaints about Matplotlib that often come up:\n",
    "\n",
    "- Prior to version 2.0, Matplotlib's defaults are not exactly the best choices. It was based off of MATLAB circa 1999, and this often shows.\n",
    "- Matplotlib's API is relatively low level. Doing sophisticated statistical visualization is possible, but often requires a *lot* of boilerplate code.\n",
    "- Matplotlib predated Pandas by more than a decade, and thus is not designed for use with Pandas ``DataFrame``s. In order to visualize data from a Pandas ``DataFrame``, you must extract each ``Series`` and often concatenate them together into the right format. It would be nicer to have a plotting library that can intelligently use the ``DataFrame`` labels in a plot.\n",
    "\n",
    "An answer to these problems is [Seaborn](http://seaborn.pydata.org/). Seaborn provides an API on top of Matplotlib that offers sane choices for plot style and color defaults, defines simple high-level functions for common statistical plot types, and integrates with the functionality provided by Pandas ``DataFrame``s.\n",
    "\n",
    "To be fair, the Matplotlib team is addressing this: it has recently added the ``plt.style`` tools discussed in [Customizing Matplotlib: Configurations and Style Sheets](04.11-Settings-and-Stylesheets.ipynb), and is starting to handle Pandas data more seamlessly.\n",
    "The 2.0 release of the library will include a new default stylesheet that will improve on the current status quo.\n",
    "But for all the reasons just discussed, Seaborn remains an extremely useful addon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Seaborn\n",
    "\n",
    "Uncomment the next cell, run it once, then comment it out &mdash; it will be installed in your environment and you won't need to run it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn Versus Matplotlib\n",
    "\n",
    "Here is an example of a simple random-walk plot in Matplotlib, using its classic plot formatting and colors.\n",
    "We start with the typical imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random walk data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some data\n",
    "rng = np.random.RandomState(0)\n",
    "x = np.linspace(0, 10, 500)\n",
    "y = np.cumsum(rng.randn(500, 6), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a simple plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data with Matplotlib defaults\n",
    "plt.plot(x, y)\n",
    "plt.legend('ABCDEF', ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the result contains all the information we'd like it to convey, it does so in a way that is not all that aesthetically pleasing, and even looks a bit old-fashioned in the context of 21st-century data visualization.\n",
    "\n",
    "Now let's take a look at how it works with Seaborn.\n",
    "As we will see, Seaborn has many of its own high-level plotting routines, but it can also overwrite Matplotlib's default parameters and in turn get even simple Matplotlib scripts to produce vastly superior output.\n",
    "We can set the style by calling Seaborn's ``set()`` method.\n",
    "By convention, Seaborn is imported as ``sns``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rerun the same two lines as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plotting code as above!\n",
    "plt.plot(x, y)\n",
    "plt.legend('ABCDEF', ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The magic is below the surface!\n",
    "\n",
    "The code still uses `plt` but the background has changed (to being gridded) and shaded in a pleasing color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations of Multivariate Data\n",
    "\n",
    "We'll be using `numpy` for generating multivariate data. Two concepts are useful as reminders:\n",
    "\n",
    "### Normal Univariate data\n",
    "\n",
    "In probability theory, a normal (or Gaussian or Gauss or Laplaceâ€“Gauss) distribution is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is\n",
    "\n",
    "\n",
    "$$\n",
    "p(x) \\sim \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp{ \\bigg[-\\frac{1}{2}\\bigg( \\frac{x-\\mu}{\\sigma}\\bigg)^2 \\bigg] }\n",
    "$$\n",
    "\n",
    "The parameter $\\mu$ is the mean or expectation of the distribution (and also its median and mode), while the parameter $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma ^2$. A random variable with a Gaussian distribution is said to be normally distributed, and is called a normal deviate.\n",
    "\n",
    "To get a feel for the function, we will plot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.1 \n",
    "x = np.random.normal(mu, sigma, size=200000)\n",
    "\n",
    "noprint = sns.distplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Data\n",
    "\n",
    "Multivariate data is an _n_-dimensional extension of the idea of normal functions. Akin to `np.random.normal(mu, sigma, ...)`, $\\mu$ becomes a location on a plane `(x, y)`. The equivalent of $\\sigma$, however, is a Covariance matrix.\n",
    "\n",
    "```\n",
    "data = np.random.multivariate_normal([0, 0], cov_mtx, size=20000)\n",
    "data = pd.DataFrame(data, columns=range(2))\n",
    "data\n",
    "```\n",
    "This covariance matrix $\\left( \\begin{array}{cc} \n",
    "cos(\\theta) & sin(\\theta) \\\\\n",
    "sin(\\theta) & cos(\\theta)\n",
    "\\end{array}\\right)\n",
    "$ indicates the level to which two variables vary together.\n",
    "Change the covariance matrix to $\\left( \\begin{array}{cc} \n",
    "cos(\\theta + \\alpha) & sin(\\theta + \\alpha) \\\\\n",
    "-sin(\\theta + \\alpha) & cos(\\theta + \\alpha)\n",
    "\\end{array}\\right)\n",
    "$ as you change $\\alpha$ from 0 to $\\pi/2$ and observe how the distribution changes.\n",
    "\n",
    "_About the multivariate_normal calculation:_ the covariance matrix must be symmetric and [positive-semidefinite](https://en.wikipedia.org/wiki/Definite_symmetric_matrix) for proper sampling. Occasionally, the matrices are flagged as _not_ positive semidefinite due to small\n",
    "floating point errors, so we correct for that up front by calculating the eigenvalues of the matrix and adding a small identity matrix if the smallest of the eigenvalues is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = math.pi/4.\n",
    "alpha = math.pi/8.\n",
    "n = 0  # vary n from 0 to 4 and observe the shape of the distribution as a function of _n_.\n",
    "cov_mtx = np.array([[ math.cos(theta+n*alpha), math.sin(theta+n*alpha)], [math.sin(theta+n*alpha),  math.cos(theta+n*alpha)]])\n",
    "\n",
    "min_eig = np.min(np.real(np.linalg.eigvals(cov_mtx)))\n",
    "if min_eig < 0:\n",
    "    cov_mtx += 1e-12 * np.eye(*cov_mtx.shape)\n",
    "\n",
    "data = np.random.multivariate_normal([0, 0], cov_mtx, size=20000)\n",
    "data = pd.DataFrame(data, columns=range(2))\n",
    "\n",
    "sns.jointplot(x=0, y=1, data=data, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we change _n_ from 0 to 4 above, observe how the values go from being perfectly correlated to uncorrelated to opposites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.multivariate_normal([0, 0], cov_mtx, size=20000)\n",
    "data = pd.DataFrame(data, columns=range(2))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Seaborn Plots\n",
    "\n",
    "The main idea of Seaborn is that it provides high-level commands to create a variety of plot types useful for statistical data exploration, and even some statistical model fitting.\n",
    "\n",
    "Let's take a look at a few of the datasets and plot types available in Seaborn. Note that all of the following *could* be done using raw Matplotlib commands (this is, in fact, what Seaborn does under the hood) but the Seaborn API is much more convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_widemat = np.array([[50,-2],[-2,1]])\n",
    "\n",
    "print (np.linalg.eigvals(data_widemat))\n",
    "pd.DataFrame(data_widemat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This covariance matrix $\\left( \\begin{array}{cc} \n",
    "50 & -2\\\\\n",
    "-2 & 1\n",
    "\\end{array}\\right)\n",
    "$ indicates the level to which two variables vary together.\n",
    "\n",
    "\n",
    "From the multivariate normal distribution, we draw N-dimensional\n",
    "samples, $ X = [x_1, x_2]. $  The covariance matrix element $ C_{ij} $ is the covariance of $ x_i $ and $x_j$.\n",
    "The element $C_{ii}$ is the variance of $x_i$ (i.e. its \"spread\").\n",
    "The negative covariances in the off-diagonal elements of the matrix indicate that the two columns are _inversely_ correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.multivariate_normal([0, 0], data_widemat, size=2000)\n",
    "data = pd.DataFrame(data, columns=['x', 'y'])\n",
    "\n",
    "for col in 'xy':\n",
    "    plt.hist(data[col], density=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothed Histograms\n",
    "\n",
    "Rather than a histogram, we can get a smooth estimate of the distribution using a _kernel density estimation_.\n",
    "\n",
    "The concept of kernel density estimation is illustrated below. The histogram (left) and kernel density estimate (right) constructed using the same data. The six individual kernels are the red dashed curves, the kernel density estimate the blue curves. The data points are the rug plot on the horizontal axis. Source, [Wikipedia](https://en.wikipedia.org/wiki/Kernel_density_estimation).\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Comparison_of_1D_histogram_and_KDE.png/500px-Comparison_of_1D_histogram_and_KDE.png)\n",
    "\n",
    "Seaborn shows kernel density estimates does with `sns.kdeplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'xy':\n",
    "    sns.kdeplot(data[col], shade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms and KDE can be combined using ``distplot``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['x'], color='lightblue')\n",
    "sns.distplot(data['y']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass the full two-dimensional dataset to ``kdeplot``, we will get a two-dimensional visualization of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "noprint = sns.kdeplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the joint distribution and the marginal distributions together using ``sns.jointplot``.\n",
    "For this plot, we'll set the style to a white background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    sns.jointplot(x = \"x\", y = \"y\", data = data, kind='kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other parameters that can be passed to ``jointplot``â€”for example, we can use a hexagonally based histogram instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    sns.jointplot(x=\"x\", y=\"y\", data=data, kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faceted histograms\n",
    "\n",
    "Sometimes the best way to view data is via histograms of subsets. Seaborn's ``FacetGrid`` makes this extremely simple.\n",
    "We'll take a look at some data that shows the amount that restaurant staff receive in tips based on various indicator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['tip_pct'] = 100 * tips['tip'] / tips['total_bill']\n",
    "\n",
    "grid = sns.FacetGrid(tips, row=\"sex\", col=\"time\", margin_titles=True)\n",
    "grid.map(plt.hist, \"tip_pct\", bins=np.linspace(0, 40, 15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor plots\n",
    "\n",
    "Factor plots can be useful for this kind of visualization as well. This allows you to view the distribution of a parameter within bins defined by any other parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(style='ticks'):\n",
    "    g = sns.catplot(x=\"day\", y=\"total_bill\", hue=\"sex\", data=tips, kind=\"box\")\n",
    "    g.set_axis_labels(\"Day\", \"Total Bill\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint distributions\n",
    "\n",
    "Similar to the pairplot we saw earlier, we can use ``sns.jointplot`` to show the joint distribution between different datasets, along with the associated marginal distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint plot can even do some automatic kernel density estimation and regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots\n",
    "\n",
    "Time series can be plotted using ``sns.factorplot``. In the following example, we'll use the Planets \n",
    "Planets dataset, available via the [Seaborn package](http://seaborn.pydata.org/). This dataset has been excerpted from the [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=PS). The excerpt has 1,035 rows but many more exoplanets have been found since and the current count in 2020 is 26,853!\n",
    "\n",
    "It gives information on planets that astronomers have discovered around other stars (known as *extrasolar planets* or *exoplanets* for short). It can be downloaded with a simple Seaborn command, `load_dataset('planets')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets = sns.load_dataset('planets')\n",
    "print(planets.shape)\n",
    "planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.catplot(x=\"year\", data=planets, aspect=2,\n",
    "                       kind=\"count\", color='steelblue')\n",
    "    g.set_xticklabels(step=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can learn more by looking at the *method* of discovery of each of these planets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.catplot(x=\"year\", data=planets, aspect=4.0, kind='count',\n",
    "                       hue='method', order=range(2001, 2015))\n",
    "    g.set_ylabels('Number of Planets Discovered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done, submit the notebook\n",
    "\n",
    "1. **Run all the cells in order.**\n",
    "\n",
    "2. Submit the notebook by saving it as PDF. \n",
    "    * In the cluster environment, it's File | Print (Save as PDF) and submit to [Gradescope](https://www.gradescope.com/courses/182658)<sup>&dagger;</sup>, \n",
    "    * On other versions, it may be File | Download As (PDF) and then submit to [Gradescope](https://www.gradescope.com/courses/182658)<sup>&dagger;</sup>.\n",
    "\n",
    "<sup>&dagger;</sup>To submit to Gradescope, log into the website, add course 9W7PW3 (if not already added) and submit. The assignment name should match the name of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The end](https://live.staticflickr.com/32/89187454_3ae6aded89_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on plotting with Seaborn, see the [Seaborn documentation](http://seaborn.pydata.org/), a [tutorial](http://seaborn.pydata.org/tutorial.htm), and the [Seaborn gallery](http://seaborn.pydata.org/examples/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Geographic Data with Basemap](04.13-Geographic-Data-With-Basemap.ipynb) | [Contents](Index.ipynb) | [Further Resources](04.15-Further-Resources.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.14-Visualization-With-Seaborn.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
